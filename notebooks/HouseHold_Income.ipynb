{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21c8e605-91ae-4739-8c4b-61c084812d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoroCode</th>\n",
       "      <th>BoroName</th>\n",
       "      <th>CountyFIPS</th>\n",
       "      <th>CDTA2020</th>\n",
       "      <th>CDTAName</th>\n",
       "      <th>CDTAType</th>\n",
       "      <th>Shape_Length</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>the_geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>47</td>\n",
       "      <td>BK02</td>\n",
       "      <td>BK02 Downtown Brooklyn-Fort Greene (CD 2 Appro...</td>\n",
       "      <td>0</td>\n",
       "      <td>65273.412132</td>\n",
       "      <td>7.592072e+07</td>\n",
       "      <td>MULTIPOLYGON (((-73.96929296348496 40.70709333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>5</td>\n",
       "      <td>BX09</td>\n",
       "      <td>BX09 Soundview-Parkchester (CD 9 Approximation)</td>\n",
       "      <td>0</td>\n",
       "      <td>70725.251197</td>\n",
       "      <td>1.124081e+08</td>\n",
       "      <td>MULTIPOLYGON (((-73.83596714156843 40.81988410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>47</td>\n",
       "      <td>BK01</td>\n",
       "      <td>BK01 Williamsburg-Greenpoint (CD 1 Equivalent)</td>\n",
       "      <td>0</td>\n",
       "      <td>65640.600849</td>\n",
       "      <td>1.316510e+08</td>\n",
       "      <td>MULTIPOLYGON (((-73.92405909736993 40.71411156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>5</td>\n",
       "      <td>BX26</td>\n",
       "      <td>BX26 Van Cortlandt Park (JIA 26 Equivalent)</td>\n",
       "      <td>1</td>\n",
       "      <td>32864.114365</td>\n",
       "      <td>5.065860e+07</td>\n",
       "      <td>MULTIPOLYGON (((-73.86789798562498 40.90294017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>5</td>\n",
       "      <td>BX08</td>\n",
       "      <td>BX08 Riverdale-Kingsbridge-Marble Hill (CD 8 A...</td>\n",
       "      <td>0</td>\n",
       "      <td>50413.975891</td>\n",
       "      <td>8.626591e+07</td>\n",
       "      <td>MULTIPOLYGON (((-73.89663333863236 40.91141737...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BoroCode  BoroName  CountyFIPS CDTA2020  \\\n",
       "16         3  Brooklyn          47     BK02   \n",
       "8          2     Bronx           5     BX09   \n",
       "15         3  Brooklyn          47     BK01   \n",
       "12         2     Bronx           5     BX26   \n",
       "7          2     Bronx           5     BX08   \n",
       "\n",
       "                                             CDTAName  CDTAType  Shape_Length  \\\n",
       "16  BK02 Downtown Brooklyn-Fort Greene (CD 2 Appro...         0  65273.412132   \n",
       "8     BX09 Soundview-Parkchester (CD 9 Approximation)         0  70725.251197   \n",
       "15     BK01 Williamsburg-Greenpoint (CD 1 Equivalent)         0  65640.600849   \n",
       "12        BX26 Van Cortlandt Park (JIA 26 Equivalent)         1  32864.114365   \n",
       "7   BX08 Riverdale-Kingsbridge-Marble Hill (CD 8 A...         0  50413.975891   \n",
       "\n",
       "      Shape_Area                                           the_geom  \n",
       "16  7.592072e+07  MULTIPOLYGON (((-73.96929296348496 40.70709333...  \n",
       "8   1.124081e+08  MULTIPOLYGON (((-73.83596714156843 40.81988410...  \n",
       "15  1.316510e+08  MULTIPOLYGON (((-73.92405909736993 40.71411156...  \n",
       "12  5.065860e+07  MULTIPOLYGON (((-73.86789798562498 40.90294017...  \n",
       "7   8.626591e+07  MULTIPOLYGON (((-73.89663333863236 40.91141737...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"raw\")\n",
    "\n",
    "median_income_df = pd.read_csv(os.path.join(DATA_DIR, \"Household_Income.csv\"))\n",
    "median_income_df.head()\n",
    "cdta_df = pd.read_csv(os.path.join(DATA_DIR, \"2020_Community_District_Tabulation.csv\"))\n",
    "cdta_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d9a7ba8-8f4d-45f8-b7a4-90aba9398212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Hold Income Columns:\n",
      " Index(['Location', 'Income Level', 'TimeFrame', 'DataFormat', 'Data', 'Fips'], dtype='object') \n",
      "\n",
      "CDTA Columns:\n",
      " Index(['BoroCode', 'BoroName', 'CountyFIPS', 'CDTA2020', 'CDTAName',\n",
      "       'CDTAType', 'Shape_Length', 'Shape_Area', 'the_geom'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Income Level</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>DataFormat</th>\n",
       "      <th>Data</th>\n",
       "      <th>Fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>Park Slope</td>\n",
       "      <td>$35,000 to $49,999</td>\n",
       "      <td>2012</td>\n",
       "      <td>Percent</td>\n",
       "      <td>0.09683</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13538</th>\n",
       "      <td>Bedford Park</td>\n",
       "      <td>$100,000 to $199,999</td>\n",
       "      <td>2018</td>\n",
       "      <td>Number</td>\n",
       "      <td>4089.00000</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9219</th>\n",
       "      <td>Queens Village</td>\n",
       "      <td>$75,000 to $99,999</td>\n",
       "      <td>2013</td>\n",
       "      <td>Percent</td>\n",
       "      <td>0.15482</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>Washington Heights</td>\n",
       "      <td>$75,000 to $99,999</td>\n",
       "      <td>2012</td>\n",
       "      <td>Number</td>\n",
       "      <td>6524.00000</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>Sheepshead Bay</td>\n",
       "      <td>$15,000 to $24,999</td>\n",
       "      <td>2008</td>\n",
       "      <td>Number</td>\n",
       "      <td>6711.00000</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Location          Income Level  TimeFrame DataFormat  \\\n",
       "7894           Park Slope    $35,000 to $49,999       2012    Percent   \n",
       "13538        Bedford Park  $100,000 to $199,999       2018     Number   \n",
       "9219       Queens Village    $75,000 to $99,999       2013    Percent   \n",
       "8071   Washington Heights    $75,000 to $99,999       2012     Number   \n",
       "3288       Sheepshead Bay    $15,000 to $24,999       2008     Number   \n",
       "\n",
       "             Data  Fips  \n",
       "7894      0.09683   306  \n",
       "13538  4089.00000   207  \n",
       "9219      0.15482   413  \n",
       "8071   6524.00000   112  \n",
       "3288   6711.00000   315  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check\n",
    "# Check columns\n",
    "print(\"House Hold Income Columns:\\n\", median_income_df.columns, \"\\n\")\n",
    "print(\"CDTA Columns:\\n\", cdta_df.columns, \"\\n\")\n",
    "median_income_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9bc9eca-0dcc-4273-abe6-f0c654a6d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame size: 35 rows x 9 columns\n"
     ]
    }
   ],
   "source": [
    "# Get the size of the dataframe\n",
    "rows, cols = cdta_df.shape\n",
    "print(f\"Merged DataFrame size: {rows} rows x {cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "10322db9-b2fe-4691-ac74-51a0529e3998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Income Level</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>DataFormat</th>\n",
       "      <th>Data</th>\n",
       "      <th>Fips</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Battery Park/Tribeca</td>\n",
       "      <td>$100,000 to $199,999</td>\n",
       "      <td>2005</td>\n",
       "      <td>Number</td>\n",
       "      <td>8039.72359</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>$100,000 to $199,999</td>\n",
       "      <td>2005</td>\n",
       "      <td>Number</td>\n",
       "      <td>11868.27641</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lower East Side</td>\n",
       "      <td>$100,000 to $199,999</td>\n",
       "      <td>2005</td>\n",
       "      <td>Number</td>\n",
       "      <td>6951.00000</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chelsea/Clinton</td>\n",
       "      <td>$100,000 to $199,999</td>\n",
       "      <td>2005</td>\n",
       "      <td>Number</td>\n",
       "      <td>10347.29257</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midtown Business District</td>\n",
       "      <td>$100,000 to $199,999</td>\n",
       "      <td>2005</td>\n",
       "      <td>Number</td>\n",
       "      <td>5178.70743</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Location          Income Level  TimeFrame DataFormat  \\\n",
       "0       Battery Park/Tribeca  $100,000 to $199,999       2005     Number   \n",
       "1          Greenwich Village  $100,000 to $199,999       2005     Number   \n",
       "2            Lower East Side  $100,000 to $199,999       2005     Number   \n",
       "3            Chelsea/Clinton  $100,000 to $199,999       2005     Number   \n",
       "4  Midtown Business District  $100,000 to $199,999       2005     Number   \n",
       "\n",
       "          Data  Fips Code  \n",
       "0   8039.72359   101  NaN  \n",
       "1  11868.27641   102  NaN  \n",
       "2   6951.00000   103  NaN  \n",
       "3  10347.29257   104  NaN  \n",
       "4   5178.70743   105  NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Extract the code in parentheses\n",
    "median_income_df['Code'] = median_income_df['Location'].str.extract(r'\\((.*?)\\)')\n",
    "median_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13107238-7829-4e3f-8a5c-1deaea38e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Replace letters only (prefix replacements)\n",
    "letter_map = {\n",
    "    \"K\": \"BK\",\n",
    "   \n",
    "    \"B\": \"BX\",\n",
    "    \"M\": \"MN\",\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce0f9e-b64e-4071-aa80-6e88f285c01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ad7aa06-b199-467e-9471-80b0bcb37519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Location          Income Level  TimeFrame DataFormat  \\\n",
      "13587  Lower East Side    $15,000 to $24,999       2018     Number   \n",
      "838        Tottenville    $75,000 to $99,999       2005     Number   \n",
      "4850     East Flatbush    $50,000 to $74,999       2009     Number   \n",
      "9437        Mott Haven  $100,000 to $199,999       2014    Percent   \n",
      "11420  Elmhurst/Corona         Under $15,000       2015    Percent   \n",
      "\n",
      "             Data  Fips  Code  \n",
      "13587  8190.00000   103   NaN  \n",
      "838    9187.00000   503   NaN  \n",
      "4850   9857.00000   317   NaN  \n",
      "9437      0.03573   201   NaN  \n",
      "11420     0.16134   404   NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to replace letters while keeping numbers\n",
    "def replace_prefix(code):\n",
    "    if pd.isna(code):\n",
    "        return code\n",
    "    for old, new in letter_map.items():\n",
    "        if code.startswith(old):\n",
    "            return new + code[len(old):]\n",
    "    return code  # leave as-is if no match\n",
    "\n",
    "median_income_df['Code'] = median_income_df['Code'].apply(replace_prefix)\n",
    "\n",
    "# Optional: check first few rows\n",
    "print(median_income_df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56312f82-364c-4e4a-86ff-ce511b8ed1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame size: 17680 rows x 7 columns\n",
      "Saved updated CSV to /Users/danielluna/Desktop/median_income_with_codes.csv\n",
      "Median Income Columns:\n",
      " Index(['Location', 'Income Level', 'TimeFrame', 'DataFormat', 'Data', 'Fips',\n",
      "       'Code'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/82/sgxft7kd6vxb73hz_4nh601w0000gn/T/ipykernel_22723/3386153353.py:27: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  merged_df[col] = merged_df[col].replace('[\\$,]', '', regex=True).astype(float)\n",
      "/var/folders/82/sgxft7kd6vxb73hz_4nh601w0000gn/T/ipykernel_22723/3386153353.py:27: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  merged_df[col] = merged_df[col].replace('[\\$,]', '', regex=True).astype(float)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and object columns for key 'Code'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMedian Income Columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, median_income_df.columns, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Inner join on Code -> CDTA2020\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m merged_df = \u001b[43mmedian_income_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcdta_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCDTA2020\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Sort the DataFrame by 'Code'\u001b[39;00m\n\u001b[32m     20\u001b[39m merged_df = merged_df.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m'\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Datathon/ds_int2_template/venv/lib/python3.13/site-packages/pandas/core/frame.py:10839\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10820\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10821\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10822\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10835\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10836\u001b[39m ) -> DataFrame:\n\u001b[32m  10837\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10848\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10849\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Datathon/ds_int2_template/venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Datathon/ds_int2_template/venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:807\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_tolerance(\u001b[38;5;28mself\u001b[39m.left_join_keys)\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Datathon/ds_int2_template/venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:1509\u001b[39m, in \u001b[36m_MergeOperation._maybe_coerce_merge_keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[32m   1504\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1505\u001b[39m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1506\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1507\u001b[39m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1508\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1511\u001b[39m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[32m   1512\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk.dtype):\n",
      "\u001b[31mValueError\u001b[39m: You are trying to merge on float64 and object columns for key 'Code'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the size of the dataframe\n",
    "rows, cols = median_income_df.shape\n",
    "print(f\"Merged DataFrame size: {rows} rows x {cols} columns\")\n",
    "\n",
    "#Step 3: Export to CSV\n",
    "output_fp = '/Users/danielluna/Desktop/median_income_with_codes.csv'\n",
    "median_income_df.to_csv(output_fp, index=False)\n",
    "print(f\"Saved updated CSV to {output_fp}\")\n",
    "print(\"Median Income Columns:\\n\", median_income_df.columns, \"\\n\")\n",
    "\n",
    "# Inner join on Code -> CDTA2020\n",
    "merged_df = median_income_df.merge(\n",
    "    cdta_df,\n",
    "    left_on='Code',\n",
    "    right_on='CDTA2020',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'Code'\n",
    "merged_df = merged_df.sort_values(by='Code').reset_index(drop=True)\n",
    "\n",
    "merged_df = merged_df[['Location','All Households','Families','Families with Children','Families without Children','Code','the_geom']]\n",
    "\n",
    "# Step 1: Strip $ and commas from income columns and convert to numeric\n",
    "income_cols = ['All Households', 'Families', 'Families with Children', 'Families without Children']\n",
    "for col in income_cols:\n",
    "    merged_df[col] = merged_df[col].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Step 2: Ensure string columns\n",
    "string_cols = ['Location', 'Code', 'the_geom']\n",
    "for col in string_cols:\n",
    "    merged_df[col] = merged_df[col].astype(str)\n",
    "\n",
    "# Quick check\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)\n",
    "# Get the size of the dataframe\n",
    "rows, cols = merged_df.shape\n",
    "print(f\"Merged DataFrame size: {rows} rows x {cols} columns\")\n",
    "\n",
    "# Optional: export to CSV\n",
    "output_fp = '/Users/danielluna/Desktop/median_income_cdta_merged.csv'\n",
    "merged_df.to_csv(output_fp, index=False)\n",
    "print(f\"Saved merged CSV to {output_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a497e53-6566-4d98-9776-1665d102cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"data\", \"raw\")\n",
    "\n",
    "\n",
    "# --- File Paths ---\n",
    "# NOTE: Please ensure you have these two files in the same directory as the script.\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    income_df = pd.read_csv(os.path.join(DATA_DIR, \"Household_Income.csv\"))\n",
    "\n",
    "    cdta_fp = pd.read_csv(os.path.join(DATA_DIR, \"2020_Community_District_Tabulation.csv\"))\n",
    "\n",
    "    print(\"Files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please make sure the correct filenames are used and the files are in the right directory.\")\n",
    "    # Exit if files cannot be loaded.\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33739e77-5f97-4e7b-8495-ded1c71af397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 'CDTACode' in the income dataframe. Head:\n",
      "                    Location  Fips CDTACode\n",
      "0       Battery Park/Tribeca   101     MN01\n",
      "1          Greenwich Village   102     MN02\n",
      "2            Lower East Side   103     MN03\n",
      "3            Chelsea/Clinton   104     MN04\n",
      "4  Midtown Business District   105     MN05\n",
      "\n",
      "Warning: 9520 rows from the income data did not find a matching geography.\n",
      "\n",
      "Filtered data to include only Brooklyn and Bronx. Resulting shape: (8160, 17)\n",
      "\n",
      "Successfully saved the filtered data to 'bronx_and_brooklyn_household_income.csv'\n",
      "\n",
      "Final data preview:\n",
      "                Location          Income Level  TimeFrame        Data  \\\n",
      "12            Mott Haven  $100,000 to $199,999       2005   667.08540   \n",
      "13           Hunts Point  $100,000 to $199,999       2005   380.91460   \n",
      "14            Morrisania  $100,000 to $199,999       2005   581.71513   \n",
      "15  Concourse/Highbridge  $100,000 to $199,999       2005  1162.00000   \n",
      "16    University Heights  $100,000 to $199,999       2005  1429.00000   \n",
      "\n",
      "   DataFormat CDTACode BoroName  \\\n",
      "12     Number     BX01    Bronx   \n",
      "13     Number     BX02    Bronx   \n",
      "14     Number     BX03    Bronx   \n",
      "15     Number     BX04    Bronx   \n",
      "16     Number     BX05    Bronx   \n",
      "\n",
      "                                             the_geom  \n",
      "12  MULTIPOLYGON (((-73.91189154987826 40.82214148...  \n",
      "13  MULTIPOLYGON (((-73.89680883223774 40.79580844...  \n",
      "14  MULTIPOLYGON (((-73.90131729886909 40.84447394...  \n",
      "15  MULTIPOLYGON (((-73.9229530705218 40.844294763...  \n",
      "16  MULTIPOLYGON (((-73.89177188666727 40.86187171...  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation ---\n",
    "\n",
    "# 1. Prepare the income data\n",
    "# The 'Fips' column seems to encode borough and district. We'll convert it to a CDTA code.\n",
    "# For example, 317 -> BK17 (Brooklyn Community District 17)\n",
    "\n",
    "# Mapping from the first digit of 'Fips' to the borough prefix\n",
    "boro_map = {\n",
    "    1: 'MN',  # Manhattan\n",
    "    2: 'BX',  # Bronx\n",
    "    3: 'BK',  # Brooklyn\n",
    "    4: 'QN',  # Queens\n",
    "    5: 'SI'   # Staten Island\n",
    "}\n",
    "\n",
    "def create_cdta_code(fips):\n",
    "    \"\"\"Converts a FIPS-like number (e.g., 317) to a CDTA code (e.g., 'BK17').\"\"\"\n",
    "    if pd.isna(fips):\n",
    "        return None\n",
    "    fips = int(fips)\n",
    "    boro_digit = fips // 100\n",
    "    district_num = fips % 100\n",
    "\n",
    "    if boro_digit not in boro_map:\n",
    "        return None\n",
    "\n",
    "    boro_prefix = boro_map[boro_digit]\n",
    "    # Format number with leading zero if needed (e.g., 1 -> '01')\n",
    "    return f'{boro_prefix}{district_num:02d}'\n",
    "\n",
    "# Create the new join key in the income dataframe\n",
    "income_df['CDTACode'] = income_df['Fips'].apply(create_cdta_code)\n",
    "print(\"\\nCreated 'CDTACode' in the income dataframe. Head:\")\n",
    "print(income_df[['Location', 'Fips', 'CDTACode']].head())\n",
    "\n",
    "\n",
    "# 2. Merge the two dataframes\n",
    "# We merge income data with geographic data on the new CDTA code.\n",
    "merged_df = income_df.merge(\n",
    "    cdta_df,\n",
    "    left_on='CDTACode',\n",
    "    right_on='CDTA2020',\n",
    "    how='left'  # Use a left join to keep all income data\n",
    ")\n",
    "\n",
    "# Check for rows that didn't merge\n",
    "unmerged_count = merged_df['the_geom'].isna().sum()\n",
    "if unmerged_count > 0:\n",
    "    print(f\"\\nWarning: {unmerged_count} rows from the income data did not find a matching geography.\")\n",
    "\n",
    "# --- Filtering ---\n",
    "\n",
    "# 3. Filter for Bronx and Brooklyn\n",
    "# We use the 'BoroName' column from the geography data to select the desired boroughs.\n",
    "# We also drop any rows that didn't have a matching geometry.\n",
    "bronx_brooklyn_df = merged_df[merged_df['BoroName'].isin(['Brooklyn', 'Bronx'])].dropna(subset=['the_geom']).copy()\n",
    "print(f\"\\nFiltered data to include only Brooklyn and Bronx. Resulting shape: {bronx_brooklyn_df.shape}\")\n",
    "\n",
    "\n",
    "# --- Final Cleanup & Export ---\n",
    "\n",
    "# 4. Clean up and select final columns for Kepler.gl\n",
    "final_cols = [\n",
    "    'Location', 'Income Level', 'TimeFrame', 'Data', 'DataFormat',\n",
    "    'CDTACode', 'BoroName', 'the_geom'\n",
    "]\n",
    "# Filter for columns that actually exist in the dataframe\n",
    "final_cols_exist = [col for col in final_cols if col in bronx_brooklyn_df.columns]\n",
    "final_df = bronx_brooklyn_df[final_cols_exist]\n",
    "\n",
    "\n",
    "# 5. Save the result to a new CSV file\n",
    "output_fp = 'bronx_and_brooklyn_household_income.csv'\n",
    "final_df.to_csv(output_fp, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully saved the filtered data to '{output_fp}'\")\n",
    "print(\"\\nFinal data preview:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "432ffd77-9391-4cac-b735-589e97181460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "try:\n",
    "    poverty_df = pd.read_csv(os.path.join(DATA_DIR, \"Poverty.csv\"))\n",
    "\n",
    "    cdta_fp = pd.read_csv(os.path.join(DATA_DIR, \"2020_Community_District_Tabulation.csv\"))\n",
    "\n",
    "    print(\"Files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please make sure the correct filenames are used and the files are in the right directory.\")\n",
    "    # Exit if files cannot be loaded.\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "581ad226-67ce-4ea2-992c-8a19298e2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 'CDTACode' in the poverty dataframe. Head:\n",
      "                    Location  Fips CDTACode\n",
      "0       Battery Park/Tribeca   101     MN01\n",
      "1          Greenwich Village   102     MN02\n",
      "2            Lower East Side   103     MN03\n",
      "3            Chelsea/Clinton   104     MN04\n",
      "4  Midtown Business District   105     MN05\n",
      "\n",
      "Warning: 1260 rows from the poverty data did not find a matching geography.\n",
      "\n",
      "Filtered data to include only Brooklyn and Bronx. Resulting shape: (1080, 16)\n",
      "\n",
      "Successfully saved the filtered data to 'bronx_and_brooklyn_poverty_data.csv'\n",
      "\n",
      "Final data preview:\n",
      "                Location  TimeFrame DataFormat         Data CDTACode BoroName  \\\n",
      "12            Mott Haven       2011     Number  36723.43294     BX01    Bronx   \n",
      "13           Hunts Point       2011     Number  20969.56706     BX02    Bronx   \n",
      "14            Morrisania       2011     Number  35195.47786     BX03    Bronx   \n",
      "15  Concourse/Highbridge       2011     Number  57290.00000     BX04    Bronx   \n",
      "16    University Heights       2011     Number  52920.00000     BX05    Bronx   \n",
      "\n",
      "                                             the_geom  \n",
      "12  MULTIPOLYGON (((-73.91189154987826 40.82214148...  \n",
      "13  MULTIPOLYGON (((-73.89680883223774 40.79580844...  \n",
      "14  MULTIPOLYGON (((-73.90131729886909 40.84447394...  \n",
      "15  MULTIPOLYGON (((-73.9229530705218 40.844294763...  \n",
      "16  MULTIPOLYGON (((-73.89177188666727 40.86187171...  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation ---\n",
    "\n",
    "# 1. Prepare the poverty data\n",
    "# Convert the 'Fips' column into a standard CDTA code (e.g., 317 -> BK17).\n",
    "boro_map = {\n",
    "    1: 'MN',  # Manhattan\n",
    "    2: 'BX',  # Bronx\n",
    "    3: 'BK',  # Brooklyn\n",
    "    4: 'QN',  # Queens\n",
    "    5: 'SI'   # Staten Island\n",
    "}\n",
    "\n",
    "def create_cdta_code(fips):\n",
    "    \"\"\"Converts a FIPS-like number (e.g., 317) to a CDTA code (e.g., 'BK17').\"\"\"\n",
    "    if pd.isna(fips):\n",
    "        return None\n",
    "    fips = int(fips)\n",
    "    boro_digit = fips // 100\n",
    "    district_num = fips % 100\n",
    "\n",
    "    if boro_digit not in boro_map:\n",
    "        return None\n",
    "\n",
    "    boro_prefix = boro_map[boro_digit]\n",
    "    # Format number with a leading zero if needed (e.g., 1 -> '01')\n",
    "    return f'{boro_prefix}{district_num:02d}'\n",
    "\n",
    "# Create the new join key in the poverty dataframe\n",
    "poverty_df['CDTACode'] = poverty_df['Fips'].apply(create_cdta_code)\n",
    "print(\"\\nCreated 'CDTACode' in the poverty dataframe. Head:\")\n",
    "print(poverty_df[['Location', 'Fips', 'CDTACode']].head())\n",
    "\n",
    "\n",
    "# 2. Merge the poverty and geography dataframes\n",
    "merged_df = poverty_df.merge(\n",
    "    cdta_df,\n",
    "    left_on='CDTACode',\n",
    "    right_on='CDTA2020',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for rows that didn't merge\n",
    "unmerged_count = merged_df['the_geom'].isna().sum()\n",
    "if unmerged_count > 0:\n",
    "    print(f\"\\nWarning: {unmerged_count} rows from the poverty data did not find a matching geography.\")\n",
    "\n",
    "\n",
    "# --- Filtering ---\n",
    "\n",
    "# 3. Filter for Bronx and Brooklyn\n",
    "# We use 'BoroName' from the geography data and drop any rows without a geometry.\n",
    "bronx_brooklyn_df = merged_df[merged_df['BoroName'].isin(['Brooklyn', 'Bronx'])].dropna(subset=['the_geom']).copy()\n",
    "print(f\"\\nFiltered data to include only Brooklyn and Bronx. Resulting shape: {bronx_brooklyn_df.shape}\")\n",
    "\n",
    "\n",
    "# --- Final Cleanup & Export ---\n",
    "\n",
    "# 4. Select and clean up the final columns for Kepler.gl\n",
    "final_cols = [\n",
    "    'Location', 'TimeFrame', 'DataFormat', 'Data',\n",
    "    'CDTACode', 'BoroName', 'the_geom'\n",
    "]\n",
    "# Ensure all selected columns exist in the DataFrame\n",
    "final_cols_exist = [col for col in final_cols if col in bronx_brooklyn_df.columns]\n",
    "final_df = bronx_brooklyn_df[final_cols_exist]\n",
    "\n",
    "\n",
    "# 5. Save the result to a new CSV file\n",
    "output_fp = 'bronx_and_brooklyn_poverty_data.csv'\n",
    "final_df.to_csv(output_fp, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully saved the filtered data to '{output_fp}'\")\n",
    "print(\"\\nFinal data preview:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35473a3b-ad35-47d0-b671-98eec9d7941e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datathon_env)",
   "language": "python",
   "name": "datathon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
